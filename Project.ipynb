{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9595516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "import graphviz\n",
    "#I Have problems with packages try running without this command \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import local_binary_pattern\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pathlib\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3365b4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "235358a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_features(image, target_size):\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the number of bins for each channel in the histogram\n",
    "    hue_bins = 8\n",
    "    saturation_bins = 8\n",
    "    value_bins = 8\n",
    "\n",
    "    # Calculate the color histogram for each channel\n",
    "    hue_hist = cv2.calcHist([hsv_image], [0], None, [hue_bins], [0, 180])\n",
    "    saturation_hist = cv2.calcHist([hsv_image], [1], None, [saturation_bins], [0, 256])\n",
    "    value_hist = cv2.calcHist([hsv_image], [2], None, [value_bins], [0, 256])\n",
    "\n",
    "    # Normalize the histograms\n",
    "    cv2.normalize(hue_hist, hue_hist, 0, 1, cv2.NORM_MINMAX)\n",
    "    cv2.normalize(saturation_hist, saturation_hist, 0, 1, cv2.NORM_MINMAX)\n",
    "    cv2.normalize(value_hist, value_hist, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    color_features = np.concatenate((hue_hist.flatten(), saturation_hist.flatten(), value_hist.flatten()))\n",
    "\n",
    "    # Resize the color features to the target size\n",
    "    if len(color_features) < target_size:\n",
    "        color_features = np.pad(color_features, (0, target_size - len(color_features)), mode='constant')\n",
    "    elif len(color_features) > target_size:\n",
    "        color_features = color_features[:target_size]\n",
    "\n",
    "    #print(\"Color features:\", color_features.shape)\n",
    "\n",
    "    return color_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c57fa583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shape_features(image, target_size):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply binary thresholding to obtain a binary image\n",
    "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialize a list to store shape features\n",
    "    shape_features = []\n",
    "\n",
    "    # Iterate over the contours\n",
    "    for contour in contours:\n",
    "        # Calculate contour-based features\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        _, _, width, height = cv2.boundingRect(contour)\n",
    "        aspect_ratio = width / float(height) if height != 0 else 0\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter != 0 else 0\n",
    "\n",
    "        # Append the shape features to the list\n",
    "        shape_features.extend([area, perimeter, aspect_ratio, circularity])\n",
    "\n",
    "    # Convert the shape features list to a numpy array\n",
    "    shape_features = np.array(shape_features)\n",
    "\n",
    "    # Resize the shape features to the target size\n",
    "    if len(shape_features) < target_size:\n",
    "        shape_features = np.pad(shape_features, (0, target_size - len(shape_features)), mode='constant')\n",
    "    elif len(shape_features) > target_size:\n",
    "        shape_features = shape_features[:target_size]\n",
    "\n",
    "    #print(\"Shape features:\", shape_features.shape)\n",
    "    return shape_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bfac841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texture_features(image, target_size):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the Local Binary Pattern (LBP) for the grayscale image\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    lbp_image = local_binary_pattern(gray_image, n_points, radius, method='uniform')\n",
    "\n",
    "    # Calculate the histogram of the LBP image\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "\n",
    "    # Flatten and return the histogram as the texture feature vector\n",
    "    texture_features = hist.flatten()\n",
    "\n",
    "    # Resize the texture features to the target size\n",
    "    if len(texture_features) < target_size:\n",
    "        texture_features = np.pad(texture_features, (0, target_size - len(texture_features)), mode='constant')\n",
    "    elif len(texture_features) > target_size:\n",
    "        texture_features = texture_features[:target_size]\n",
    "\n",
    "    #print(\"Texture features:\", texture_features.shape)\n",
    "\n",
    "    return texture_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "515f78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(image):\n",
    "    # Load and preprocess the image\n",
    "    # Assuming image is already loaded or you can use OpenCV to load it\n",
    "    preprocessed_image = image\n",
    "    #print(preprocessed_image)\n",
    "\n",
    "    # Extract features using different methods\n",
    "    color_features = extract_color_features(preprocessed_image,60)\n",
    "    shape_features = extract_shape_features(preprocessed_image,50)\n",
    "    texture_features = extract_texture_features(preprocessed_image,10)\n",
    "\n",
    "    # Combine the features into a single vector\n",
    "    #print(color_features.shape, shape_features.shape, texture_features.shape)\n",
    "    combined_features = np.concatenate((color_features, shape_features, texture_features),axis=None)\n",
    "\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9286e9c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#folder_path = \"/Users/hadi/Desktop/Concordia/Comp 6721/AIproject/fruits/training/Kiwi_Training\"\n",
    "\n",
    "def generate_features(image):\n",
    "    #image = cv2.imread(image_path)\n",
    "    #new_size = (32, 32)\n",
    "    #image = cv2.resize(image, new_size)\n",
    "    combined_features = combine_features(image)\n",
    "    return combined_features\n",
    "\n",
    "def check_label(element):\n",
    "    if element == 'Banana_Training' or element == \"Banana_Test\" or element == \"Banana_Validation\":\n",
    "        return 1\n",
    "    elif element == 'Kiwi_Training' or element == \"Kiwi_Test\" or element == \"Kiwi_Validation\":\n",
    "        return 2\n",
    "    elif element == 'Mango_Training' or element == \"Mango_Test\" or element == \"Mango_Validation\":\n",
    "        return 3\n",
    "    elif element == 'Orange_Training' or element == \"Orange_Test\" or element == \"Orange_Validation\":\n",
    "        return 4\n",
    "    elif element == 'Plum_Training' or element == \"Plum_Test\" or element == \"Plum_Validation\":\n",
    "        return 5\n",
    "    elif element == 'Apple_Training' or element == \"Apple_Test\" or  element == \"Apple_Validation\":\n",
    "        return 6\n",
    "    else:\n",
    "        return 0  # Return 0 if the element is not found in the list\n",
    "\n",
    "def loadImages(folder_path,class_):\n",
    "    #print(folder_path)\n",
    "    folder_path = folder_path\n",
    "    file_list = os.listdir(folder_path)\n",
    "    class_features = np.empty((0,121))\n",
    "    for file_name in file_list:\n",
    "         if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
    "             image_path = os.path.join(folder_path, file_name)\n",
    "             # Perform your image processing tasks here\n",
    "             image = cv2.imread(image_path)\n",
    "             new_size = (32, 32)\n",
    "             image = cv2.resize(image, new_size)\n",
    "             combined_features = combine_features(image)\n",
    "             #print(check_label(class_))\n",
    "             combined_features = np.append(combined_features, check_label(class_))\n",
    "             #print(combined_features.shape)\n",
    "             combined_features = np.expand_dims(combined_features, axis=0)\n",
    "             class_features = np.append(class_features, combined_features,axis=0)\n",
    "    #print(class_features[0])\n",
    "    return class_features\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "#Print the shape of the combined feature vector\n",
    "#loadImages(folder_path,\"Kiwi_Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f2087be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/Users/hadi/Desktop/Concordia/Comp 6721/AIproject/fruits/training\"\n",
    "test_path = \"/Users/hadi/Desktop/Concordia/Comp 6721/AIproject/fruits/testing\"\n",
    "val_path = \"/Users/hadi/Desktop/Concordia/Comp 6721/AIproject/fruits/validation\"\n",
    "\n",
    "root_training=pathlib.Path(train_path)\n",
    "root_testing=pathlib.Path(test_path)\n",
    "root_val = pathlib.Path(val_path)\n",
    "\n",
    "\n",
    "def generate_feature_vector(root,path):\n",
    "    classes = []\n",
    "    features = np.empty((0,121))\n",
    "    labels = []\n",
    "    for class_dir in root.iterdir():\n",
    "        class_ = class_dir.name.split('/')[-1]\n",
    "        print(class_)\n",
    "        path_ = path +\"/\"\n",
    "        if(class_!=\".DS_Store\"):\n",
    "            print(class_)\n",
    "            path_ = path+\"/\"+class_\n",
    "            temp = loadImages(path_,class_)\n",
    "            path_ = \"\"\n",
    "            classes.append(class_)\n",
    "            features = np.append(features, temp,axis=0)\n",
    "                \n",
    "    return features \n",
    "#classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "#print(classes) #['Banana_Training', 'Kiwi_Training', 'Mango_Training', 'Orange_Training', 'Plum_Training', 'Apple_Training']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d216be2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banana_Training\n",
      "Banana_Training\n",
      ".DS_Store\n",
      "Kiwi_Training\n",
      "Kiwi_Training\n",
      "Mango_Training\n",
      "Mango_Training\n",
      "Orange_Training\n",
      "Orange_Training\n",
      "Plum_Training\n",
      "Plum_Training\n",
      "Apple_Training\n",
      "Apple_Training\n",
      ".DS_Store\n",
      "Kiwi_Test\n",
      "Kiwi_Test\n",
      "Plum_Test\n",
      "Plum_Test\n",
      "Orange_Test\n",
      "Orange_Test\n",
      "Apple_Test\n",
      "Apple_Test\n",
      "Mango_Test\n",
      "Mango_Test\n",
      "Banana_Test\n",
      "Banana_Test\n",
      ".DS_Store\n",
      "Mango_Validation\n",
      "Mango_Validation\n",
      "Plum_Validation\n",
      "Plum_Validation\n",
      "Banana_Validation\n",
      "Banana_Validation\n",
      "Apple_Validation\n",
      "Apple_Validation\n",
      "Kiwi_Validation\n",
      "Kiwi_Validation\n",
      "Orange_Validation\n",
      "Orange_Validation\n",
      "(14676, 121)\n",
      "(4583, 121)\n",
      "(3677, 121)\n"
     ]
    }
   ],
   "source": [
    "#calculate size of training and testing images \n",
    "\n",
    "f = generate_feature_vector(root_training,train_path) #total training features \n",
    "t = generate_feature_vector(root_testing,test_path) #total testing features\n",
    "v = generate_feature_vector(root_val,val_path) #total val features\n",
    "\n",
    "print(f.shape)\n",
    "print(t.shape)\n",
    "print(v.shape)\n",
    "#train_count = len(glob.glob(train_path+\"/**/*.png\"))\n",
    "#test_count = len(glob.glob(test_path+\"/**/*.png\"))\n",
    "\n",
    "#print(train_count,test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8c553e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.69      0.67       485\n",
      "         2.0       0.86      0.91      0.88       686\n",
      "         3.0       0.73      0.77      0.75       665\n",
      "         4.0       0.92      0.92      0.92       482\n",
      "         5.0       0.94      0.93      0.94       368\n",
      "         6.0       0.92      0.83      0.87       991\n",
      "\n",
      "    accuracy                           0.84      3677\n",
      "   macro avg       0.84      0.84      0.84      3677\n",
      "weighted avg       0.84      0.84      0.84      3677\n",
      "\n",
      "Confusion Matrix:\n",
      " [[333  11 124  12   1   4]\n",
      " [ 12 621  24   1   7  21]\n",
      " [ 88  23 509  10   1  34]\n",
      " [  9   4  11 442   2  14]\n",
      " [  7  14   0   0 344   3]\n",
      " [ 55  51  33  17  10 825]]\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "\n",
    "xtrain = f[:,:-1]\n",
    "ytrain = f[:,-1]\n",
    "xval = v[:,:-1]\n",
    "yval = v[:,-1]\n",
    "\n",
    "# xtotal = np.vstack((xtrain, xval))\n",
    "# ytotal = np.concatenate((ytrain, yval))\n",
    "\n",
    "# print(\"Features for training:\" ,xtrain)\n",
    "# print(\"Labels for training\", ytrain)\n",
    "# print(\"Features for testing:\", xtest)\n",
    "# with np.printoptions(threshold=sys.maxsize):\n",
    "#     print(\"Labels for training\", xtotal)\n",
    "#     print(\"Labels for testing\", ytotal)\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtc.fit(xtrain, ytrain)\n",
    "\n",
    "y_pred = dtc.predict(xval)\n",
    "\n",
    "print(classification_report(yval, y_pred)) #metrics values\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(yval, y_pred)) #confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4c85a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypertune parameters\n",
    "\n",
    "# xval = f[:,:-1]\n",
    "# yval = f[:,-1]\n",
    "\n",
    "#google how to hypertune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7506ec94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.71      0.66      0.69       605\n",
      "         2.0       0.81      0.89      0.85       858\n",
      "         3.0       0.74      0.83      0.78       831\n",
      "         4.0       0.94      0.95      0.95       603\n",
      "         5.0       0.92      0.95      0.94       460\n",
      "         6.0       0.89      0.76      0.82      1226\n",
      "\n",
      "    accuracy                           0.83      4583\n",
      "   macro avg       0.83      0.84      0.84      4583\n",
      "weighted avg       0.83      0.83      0.83      4583\n",
      "\n",
      "Confusion Matrix:\n",
      " [[402   9 173   5   1  15]\n",
      " [ 19 764  16   1   7  51]\n",
      " [ 71  15 692  15   2  36]\n",
      " [  4   1  12 573   2  11]\n",
      " [  3  12   0   0 438   7]\n",
      " [ 68 146  44  15  24 929]]\n"
     ]
    }
   ],
   "source": [
    "# #Model Training and saving best model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xtest = t[:,:-1]\n",
    "ytest = t[:,-1]\n",
    "\n",
    "y_pred = dtc.predict(xtest)\n",
    "\n",
    "print(classification_report(ytest, y_pred)) #metrics values\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(ytest, y_pred)) #confusion matrix\n",
    "\n",
    "#plotting tree\n",
    "# tree.plot_tree(dtc)\n",
    "# elements = [\"color\"] * 24 + [\"shape\"] * 20 + [\"texture\"] * 10\n",
    "# dot_data = tree.export_graphviz(dtc, out_file=None, feature_names=elements, class_names=['Banana', 'Apple',\"Orange\",\"Plum\",\"Mango\",\"Kiwi\"],filled=True, rounded=True)\n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph.render(\"mytree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40145d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
