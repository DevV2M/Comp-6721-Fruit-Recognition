{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9595516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "import graphviz\n",
    "#I Have problems with packages try running without this command \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import local_binary_pattern\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pathlib\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3365b4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "235358a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_features(image, target_size):\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the number of bins for each channel in the histogram\n",
    "    hue_bins = 8\n",
    "    saturation_bins = 8\n",
    "    value_bins = 8\n",
    "\n",
    "    # Calculate the color histogram for each channel\n",
    "    hue_hist = cv2.calcHist([hsv_image], [0], None, [hue_bins], [0, 180])\n",
    "    saturation_hist = cv2.calcHist([hsv_image], [1], None, [saturation_bins], [0, 256])\n",
    "    value_hist = cv2.calcHist([hsv_image], [2], None, [value_bins], [0, 256])\n",
    "\n",
    "    # Normalize the histograms\n",
    "    cv2.normalize(hue_hist, hue_hist, 0, 1, cv2.NORM_MINMAX)\n",
    "    cv2.normalize(saturation_hist, saturation_hist, 0, 1, cv2.NORM_MINMAX)\n",
    "    cv2.normalize(value_hist, value_hist, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    color_features = np.concatenate((hue_hist.flatten(), saturation_hist.flatten(), value_hist.flatten()))\n",
    "\n",
    "    # Resize the color features to the target size\n",
    "    if len(color_features) < target_size:\n",
    "        color_features = np.pad(color_features, (0, target_size - len(color_features)), mode='constant')\n",
    "    elif len(color_features) > target_size:\n",
    "        color_features = color_features[:target_size]\n",
    "\n",
    "    #print(\"Color features:\", color_features.shape)\n",
    "\n",
    "    return color_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c57fa583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shape_features(image, target_size):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply binary thresholding to obtain a binary image\n",
    "    _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialize a list to store shape features\n",
    "    shape_features = []\n",
    "\n",
    "    # Iterate over the contours\n",
    "    for contour in contours:\n",
    "        # Calculate contour-based features\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        _, _, width, height = cv2.boundingRect(contour)\n",
    "        aspect_ratio = width / float(height) if height != 0 else 0\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter != 0 else 0\n",
    "\n",
    "        # Append the shape features to the list\n",
    "        shape_features.extend([area, perimeter, aspect_ratio, circularity])\n",
    "\n",
    "    # Convert the shape features list to a numpy array\n",
    "    shape_features = np.array(shape_features)\n",
    "\n",
    "    # Resize the shape features to the target size\n",
    "    if len(shape_features) < target_size:\n",
    "        shape_features = np.pad(shape_features, (0, target_size - len(shape_features)), mode='constant')\n",
    "    elif len(shape_features) > target_size:\n",
    "        shape_features = shape_features[:target_size]\n",
    "\n",
    "    #print(\"Shape features:\", shape_features.shape)\n",
    "    return shape_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ad5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texture_features(image, target_size):\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the Local Binary Pattern (LBP) for the grayscale image\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    lbp_image = local_binary_pattern(gray_image, n_points, radius, method='uniform')\n",
    "\n",
    "    # Calculate the histogram of the LBP image\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "\n",
    "    # Flatten and return the histogram as the texture feature vector\n",
    "    texture_features = hist.flatten()\n",
    "\n",
    "    # Resize the texture features to the target size\n",
    "    if len(texture_features) < target_size:\n",
    "        texture_features = np.pad(texture_features, (0, target_size - len(texture_features)), mode='constant')\n",
    "    elif len(texture_features) > target_size:\n",
    "        texture_features = texture_features[:target_size]\n",
    "\n",
    "    #print(\"Texture features:\", texture_features.shape)\n",
    "\n",
    "    return texture_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fedbc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(image):\n",
    "    # Load and preprocess the image\n",
    "    # Assuming image is already loaded or you can use OpenCV to load it\n",
    "    preprocessed_image = image\n",
    "    #print(preprocessed_image)\n",
    "\n",
    "    # Extract features using different methods\n",
    "    color_features = extract_color_features(preprocessed_image,24)\n",
    "    shape_features = extract_shape_features(preprocessed_image,20)\n",
    "    texture_features = extract_texture_features(preprocessed_image,10)\n",
    "\n",
    "    # Combine the features into a single vector\n",
    "    #print(color_features.shape, shape_features.shape, texture_features.shape)\n",
    "    combined_features = np.concatenate((color_features, shape_features, texture_features),axis=None)\n",
    "\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6ce83de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00609756, 0.45731705, 0.99999994, ..., 0.08105469, 0.15917969,\n",
       "        2.        ],\n",
       "       [0.02760736, 0.42331287, 0.77300608, ..., 0.09863281, 0.1796875 ,\n",
       "        2.        ],\n",
       "       [0.01038961, 0.76363635, 1.        , ..., 0.08398437, 0.16210937,\n",
       "        2.        ],\n",
       "       ...,\n",
       "       [0.16007906, 1.00000012, 0.24308302, ..., 0.08203125, 0.15039062,\n",
       "        2.        ],\n",
       "       [0.07009345, 0.66121495, 0.99999994, ..., 0.08007812, 0.13769531,\n",
       "        2.        ],\n",
       "       [0.02680965, 0.91420913, 1.        , ..., 0.078125  , 0.16308594,\n",
       "        2.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "folder_path = \"/Users/hadi/Desktop/Concordia/Comp 6721/AIproject/fruits/training/Kiwi_Training\"\n",
    "\n",
    "def generate_features(image):\n",
    "    #image = cv2.imread(image_path)\n",
    "    #new_size = (32, 32)\n",
    "    #image = cv2.resize(image, new_size)\n",
    "    combined_features = combine_features(image)\n",
    "    return combined_features\n",
    "\n",
    "def check_label(element):\n",
    "    if element == 'Banana_Training':\n",
    "        return 1\n",
    "    elif element == 'Kiwi_Training':\n",
    "        return 2\n",
    "    elif element == 'Mango_Training':\n",
    "        return 3\n",
    "    elif element == 'Orange_Training':\n",
    "        return 4\n",
    "    elif element == 'Plum_Training':\n",
    "        return 5\n",
    "    elif element == 'Apple_Training':\n",
    "        return 6\n",
    "    else:\n",
    "        return 0  # Return 0 if the element is not found in the list\n",
    "\n",
    "def loadImages(folder_path,class_):\n",
    "    #print(folder_path)\n",
    "    folder_path = folder_path\n",
    "    file_list = os.listdir(folder_path)\n",
    "    class_features = np.empty((0,55))\n",
    "    count = 0 \n",
    "    for file_name in file_list:\n",
    "         if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
    "             image_path = os.path.join(folder_path, file_name)\n",
    "             # Perform your image processing tasks here\n",
    "             image = cv2.imread(image_path)\n",
    "             new_size = (32, 32)\n",
    "             image = cv2.resize(image, new_size)\n",
    "             combined_features = combine_features(image)\n",
    "             combined_features = np.append(combined_features, check_label(class_))\n",
    "             combined_features = np.expand_dims(combined_features, axis=0)\n",
    "             class_features = np.append(class_features, combined_features,axis=0)\n",
    "    return class_features\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "#Print the shape of the combined feature vector\n",
    "loadImages(folder_path,\"Kiwi_Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5383e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/Users/hadi/Desktop/Concordia/Comp 6721/AIproject/fruits/training\"\n",
    "test_path = \"/Users/hadi/Desktop/Concordia/Comp 6721/AIproject/fruits/testing\"\n",
    "\n",
    "root_training=pathlib.Path(train_path)\n",
    "root_testing=pathlib.Path(test_path)\n",
    "\n",
    "\n",
    "def generate_feature_vector(root):\n",
    "    classes = []\n",
    "    features = np.empty((0,55))\n",
    "    labels = []\n",
    "    for class_dir in root.iterdir():\n",
    "        class_ = class_dir.name.split('/')[-1]\n",
    "        path = train_path +\"/\"\n",
    "        if(class_!=\".DS_Store\"):\n",
    "            print(class_)\n",
    "            path = path+class_\n",
    "            temp = loadImages(path,class_)\n",
    "            path = \"\"\n",
    "            classes.append(class_)\n",
    "            features = np.append(features, temp,axis=0)\n",
    "                \n",
    "    return features \n",
    "#classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "#print(classes) #['Banana_Training', 'Kiwi_Training', 'Mango_Training', 'Orange_Training', 'Plum_Training', 'Apple_Training']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7279507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banana_Training\n"
     ]
    }
   ],
   "source": [
    "#calculate size of training and testing images \n",
    "\n",
    "f = generate_feature_vector(root_training) #total training features \n",
    "t = generate_feature_vector(root_testing) #total testing features\n",
    "print(f.shape)\n",
    "print(t.shape)\n",
    "#train_count = len(glob.glob(train_path+\"/**/*.png\"))\n",
    "#test_count = len(glob.glob(test_path+\"/**/*.png\"))\n",
    "\n",
    "#print(train_count,test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0001f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Model Training and saving best model\n",
    "\n",
    "\n",
    "xtrain = f[:,:-1]\n",
    "ytrain = f[:,-1]\n",
    "\n",
    "xtest = t[:,:-1]\n",
    "ytest = t[:,:-1]\n",
    "\n",
    "print(xtrain)\n",
    "print(ytrain)\n",
    "print(xtest)\n",
    "print(ytest)\n",
    "\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtc.fit(x_, y_)\n",
    "# tree.plot_tree(dtc)\n",
    "# elements = [\"color\"] * 24 + [\"shape\"] * 20 + [\"texture\"] * 10\n",
    "# dot_data = tree.export_graphviz(dtc, out_file=None, feature_names=elements, class_names=['Banana', 'Apple',\"Orange\",\"Plum\",\"Mango\",\"Kiwi\"],filled=True, rounded=True)\n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph.render(\"mytree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1de134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Graphviz in /Users/hadi/opt/anaconda3/lib/python3.9/site-packages (0.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce41c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
